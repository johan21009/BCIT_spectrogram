{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e88561-d705-4ab9-aacf-d21a82b911de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:07.759420Z",
     "iopub.status.busy": "2025-04-15T14:33:07.759001Z",
     "iopub.status.idle": "2025-04-15T14:33:08.874769Z",
     "shell.execute_reply": "2025-04-15T14:33:08.873953Z",
     "shell.execute_reply.started": "2025-04-15T14:33:07.759357Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#class_names = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b13e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:09.614132Z",
     "iopub.status.busy": "2025-04-15T14:33:09.613787Z",
     "iopub.status.idle": "2025-04-15T14:33:09.619876Z",
     "shell.execute_reply": "2025-04-15T14:33:09.619088Z",
     "shell.execute_reply.started": "2025-04-15T14:33:09.614117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/castrogaray-j'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89aeb54-9a07-4098-b9ca-3223f628b141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:09.861645Z",
     "iopub.status.busy": "2025-04-15T14:33:09.861367Z",
     "iopub.status.idle": "2025-04-15T14:33:10.436275Z",
     "shell.execute_reply": "2025-04-15T14:33:10.435533Z",
     "shell.execute_reply.started": "2025-04-15T14:33:09.861624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>reaction times</th>\n",
       "      <th>subject</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>drop 10</th>\n",
       "      <th>drop 20</th>\n",
       "      <th>3 classes</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403271</th>\n",
       "      <td>161</td>\n",
       "      <td>2.472656</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403272</th>\n",
       "      <td>161</td>\n",
       "      <td>2.472656</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403273</th>\n",
       "      <td>161</td>\n",
       "      <td>2.472656</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403274</th>\n",
       "      <td>161</td>\n",
       "      <td>2.472656</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403275</th>\n",
       "      <td>161</td>\n",
       "      <td>2.472656</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403276 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        event  reaction times  subject  class  label  drop 10  drop 20  \\\n",
       "0           1        1.676758        1      1    0.0      0.0      0.0   \n",
       "1           1        1.676758        1      1    0.0      0.0      0.0   \n",
       "2           1        1.676758        1      1    0.0      0.0      0.0   \n",
       "3           1        1.676758        1      1    0.0      0.0      0.0   \n",
       "4           1        1.676758        1      1    0.0      0.0      0.0   \n",
       "...       ...             ...      ...    ...    ...      ...      ...   \n",
       "403271    161        2.472656       21      3    1.0      1.0      1.0   \n",
       "403272    161        2.472656       21      3    1.0      1.0      1.0   \n",
       "403273    161        2.472656       21      3    1.0      1.0      1.0   \n",
       "403274    161        2.472656       21      3    1.0      1.0      1.0   \n",
       "403275    161        2.472656       21      3    1.0      1.0      1.0   \n",
       "\n",
       "        3 classes                                               path  \n",
       "0             0.0  /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "1             0.0  /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "2             0.0  /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "3             0.0  /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "4             0.0  /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "...           ...                                                ...  \n",
       "403271        2.0  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403272        2.0  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403273        2.0  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403274        2.0  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403275        2.0  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "\n",
       "[403276 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/castrogaray-j/U_Winnipeg_OneDrive/Digital_image_processing/BCIT_spectrogram')\n",
    "df1 = pd.read_csv('CH_ERDS_paths_with_labels.csv')\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34120e91-c2a0-47ca-a8cc-89d1f04e7dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a292f9-fcc1-4467-9389-b18a702d4431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:10.768731Z",
     "iopub.status.busy": "2025-04-15T14:33:10.768449Z",
     "iopub.status.idle": "2025-04-15T14:33:10.810579Z",
     "shell.execute_reply": "2025-04-15T14:33:10.809906Z",
     "shell.execute_reply.started": "2025-04-15T14:33:10.768706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction times</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.676758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.676758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.676758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.676758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.676758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_1_class_1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403271</th>\n",
       "      <td>2.472656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403272</th>\n",
       "      <td>2.472656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403273</th>\n",
       "      <td>2.472656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403274</th>\n",
       "      <td>2.472656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403275</th>\n",
       "      <td>2.472656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/data/castrogaray-j/CH_ERDS/subject_21_class_3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354425 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reaction times  label  \\\n",
       "0             1.676758    0.0   \n",
       "1             1.676758    0.0   \n",
       "2             1.676758    0.0   \n",
       "3             1.676758    0.0   \n",
       "4             1.676758    0.0   \n",
       "...                ...    ...   \n",
       "403271        2.472656    1.0   \n",
       "403272        2.472656    1.0   \n",
       "403273        2.472656    1.0   \n",
       "403274        2.472656    1.0   \n",
       "403275        2.472656    1.0   \n",
       "\n",
       "                                                     path  \n",
       "0       /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "1       /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "2       /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "3       /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "4       /data/castrogaray-j/CH_ERDS/subject_1_class_1_...  \n",
       "...                                                   ...  \n",
       "403271  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403272  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403273  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403274  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "403275  /data/castrogaray-j/CH_ERDS/subject_21_class_3...  \n",
       "\n",
       "[354425 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.drop(['class', 'subject', 'event', 'drop 20', 'label', '3 classes'], axis=1)\n",
    "df = df.dropna()\n",
    "df.rename(columns={'drop 10': 'label'}, inplace=True)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b6bbbb-3a76-4723-82a6-97a7044a9441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:11.961942Z",
     "iopub.status.busy": "2025-04-15T14:33:11.961569Z",
     "iopub.status.idle": "2025-04-15T14:33:11.966144Z",
     "shell.execute_reply": "2025-04-15T14:33:11.965162Z",
     "shell.execute_reply.started": "2025-04-15T14:33:11.961910Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.iloc[:, :64].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c03f4e-fa08-4c2e-afac-236a762668ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:13.439955Z",
     "iopub.status.busy": "2025-04-15T14:33:13.439743Z",
     "iopub.status.idle": "2025-04-15T14:33:13.444859Z",
     "shell.execute_reply": "2025-04-15T14:33:13.444275Z",
     "shell.execute_reply.started": "2025-04-15T14:33:13.439938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4097.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*4.0009765625 / 1\n",
    "#int(1024*4 /16)\n",
    "#46918602 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8fe4f-2783-427e-b125-5cba36a46cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:13.801576Z",
     "iopub.status.busy": "2025-04-15T14:33:13.801351Z",
     "iopub.status.idle": "2025-04-15T14:57:58.170427Z",
     "shell.execute_reply": "2025-04-15T14:57:58.169885Z",
     "shell.execute_reply.started": "2025-04-15T14:33:13.801559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.22      0.33      1841\n",
      "         1.0       0.60      0.89      0.72      2411\n",
      "\n",
      "    accuracy                           0.60      4252\n",
      "   macro avg       0.60      0.56      0.52      4252\n",
      "weighted avg       0.60      0.60      0.55      4252\n",
      "\n",
      "auc:0.6080193058656785 accuracy:0.6015992474129821\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6015992474129821\n",
      "Epoch 3/10, Loss: 0.2682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.53      0.65      1841\n",
      "         1.0       0.72      0.92      0.81      2411\n",
      "\n",
      "    accuracy                           0.75      4252\n",
      "   macro avg       0.78      0.73      0.73      4252\n",
      "weighted avg       0.77      0.75      0.74      4252\n",
      "\n",
      "auc:0.8364786958920627 accuracy:0.7521166509877705\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7521166509877705\n",
      "Epoch 5/10, Loss: 0.0084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.71      0.75      1841\n",
      "         1.0       0.79      0.85      0.82      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.79      0.78      0.78      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8593610986761517 accuracy:0.7909219190968956\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7909219190968956\n",
      "Epoch 7/10, Loss: 0.0332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74      1841\n",
      "         1.0       0.79      0.85      0.82      2411\n",
      "\n",
      "    accuracy                           0.78      4252\n",
      "   macro avg       0.78      0.77      0.78      4252\n",
      "weighted avg       0.78      0.78      0.78      4252\n",
      "\n",
      "auc:0.855080969420664 accuracy:0.7833960489181562\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7833960489181562\n",
      "Epoch 9/10, Loss: 0.0041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.72      0.74      1841\n",
      "         1.0       0.79      0.82      0.81      2411\n",
      "\n",
      "    accuracy                           0.78      4252\n",
      "   macro avg       0.77      0.77      0.77      4252\n",
      "weighted avg       0.78      0.78      0.78      4252\n",
      "\n",
      "auc:0.8522756125678727 accuracy:0.7775164628410159\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7775164628410159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.67      0.73      1841\n",
      "         1.0       0.78      0.88      0.83      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.79      0.77      0.78      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8633774090371151 accuracy:0.7888052681091251\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7888052681091251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f7d2ae389e4742a5aa14a1f3f5c9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.47      0.52      1841\n",
      "         1.0       0.65      0.75      0.69      2411\n",
      "\n",
      "    accuracy                           0.63      4252\n",
      "   macro avg       0.62      0.61      0.61      4252\n",
      "weighted avg       0.62      0.63      0.62      4252\n",
      "\n",
      "auc:0.6432517447305499 accuracy:0.6277046095954845\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6277046095954845\n",
      "Epoch 3/10, Loss: 0.1935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.69      0.73      1841\n",
      "         1.0       0.78      0.84      0.81      2411\n",
      "\n",
      "    accuracy                           0.78      4252\n",
      "   macro avg       0.77      0.77      0.77      4252\n",
      "weighted avg       0.77      0.78      0.77      4252\n",
      "\n",
      "auc:0.842239455185821 accuracy:0.7753998118532456\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7753998118532456\n",
      "Epoch 5/10, Loss: 0.0080\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.65      0.73      1841\n",
      "         1.0       0.77      0.89      0.83      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.80      0.77      0.78      4252\n",
      "weighted avg       0.79      0.79      0.78      4252\n",
      "\n",
      "auc:0.8621779455064162 accuracy:0.7876293508936971\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7876293508936971\n",
      "Epoch 7/10, Loss: 0.0145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.80      0.77      1841\n",
      "         1.0       0.84      0.78      0.81      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.79      0.79      0.79      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8731251905139645 accuracy:0.7902163687676388\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7902163687676388\n",
      "Epoch 9/10, Loss: 0.2397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      1841\n",
      "         1.0       0.81      0.82      0.82      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.78      0.78      0.78      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8649450024342982 accuracy:0.7880997177798683\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7880997177798683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      1841\n",
      "         1.0       0.81      0.82      0.82      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.78      0.78      0.78      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8649450024342982 accuracy:0.7880997177798683\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7880997177798683\n",
      "Epoch 1/10, Loss: 0.7223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.00      0.01      1841\n",
      "         1.0       0.57      1.00      0.72      2411\n",
      "\n",
      "    accuracy                           0.57      4252\n",
      "   macro avg       0.70      0.50      0.36      4252\n",
      "weighted avg       0.68      0.57      0.41      4252\n",
      "\n",
      "auc:0.583832790638417 accuracy:0.5679680150517403\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5679680150517403\n",
      "Epoch 3/10, Loss: 0.6431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.47      0.55      1841\n",
      "         1.0       0.67      0.82      0.74      2411\n",
      "\n",
      "    accuracy                           0.67      4252\n",
      "   macro avg       0.67      0.65      0.65      4252\n",
      "weighted avg       0.67      0.67      0.66      4252\n",
      "\n",
      "auc:0.7125085977699082 accuracy:0.6698024459078081\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6698024459078081\n",
      "Epoch 5/10, Loss: 0.1648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.62      0.65      1841\n",
      "         1.0       0.73      0.78      0.75      2411\n",
      "\n",
      "    accuracy                           0.71      4252\n",
      "   macro avg       0.70      0.70      0.70      4252\n",
      "weighted avg       0.71      0.71      0.71      4252\n",
      "\n",
      "auc:0.7535938283951589 accuracy:0.7074317968015051\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7074317968015051\n",
      "Epoch 7/10, Loss: 0.0266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.81      0.67      1841\n",
      "         1.0       0.79      0.54      0.64      2411\n",
      "\n",
      "    accuracy                           0.66      4252\n",
      "   macro avg       0.68      0.68      0.66      4252\n",
      "weighted avg       0.70      0.66      0.65      4252\n",
      "\n",
      "auc:0.7535181297200433 accuracy:0.6571025399811853\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6571025399811853\n",
      "Epoch 9/10, Loss: 0.1017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.81      0.67      1841\n",
      "         1.0       0.79      0.56      0.65      2411\n",
      "\n",
      "    accuracy                           0.66      4252\n",
      "   macro avg       0.68      0.68      0.66      4252\n",
      "weighted avg       0.70      0.66      0.66      4252\n",
      "\n",
      "auc:0.7545121254182858 accuracy:0.6639228598306679\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6639228598306679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.67      0.65      1841\n",
      "         1.0       0.74      0.71      0.72      2411\n",
      "\n",
      "    accuracy                           0.69      4252\n",
      "   macro avg       0.69      0.69      0.69      4252\n",
      "weighted avg       0.69      0.69      0.69      4252\n",
      "\n",
      "auc:0.7461242165694038 accuracy:0.6904985888993415\n",
      "Params: {'epochs': 10, 'lr': 1e-05, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6904985888993415\n",
      "Epoch 1/10, Loss: 0.6838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.12      0.20      1841\n",
      "         1.0       0.58      0.93      0.71      2411\n",
      "\n",
      "    accuracy                           0.58      4252\n",
      "   macro avg       0.57      0.52      0.46      4252\n",
      "weighted avg       0.57      0.58      0.49      4252\n",
      "\n",
      "auc:0.5868161294952002 accuracy:0.5785512699905927\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5785512699905927\n",
      "Epoch 3/10, Loss: 0.5346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.55      0.58      1841\n",
      "         1.0       0.68      0.73      0.70      2411\n",
      "\n",
      "    accuracy                           0.65      4252\n",
      "   macro avg       0.64      0.64      0.64      4252\n",
      "weighted avg       0.65      0.65      0.65      4252\n",
      "\n",
      "auc:0.6997621574663113 accuracy:0.650752587017874\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.650752587017874\n",
      "Epoch 5/10, Loss: 0.2912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.52      0.62      1841\n",
      "         1.0       0.70      0.87      0.78      2411\n",
      "\n",
      "    accuracy                           0.72      4252\n",
      "   macro avg       0.73      0.70      0.70      4252\n",
      "weighted avg       0.73      0.72      0.71      4252\n",
      "\n",
      "auc:0.7921620780728198 accuracy:0.7198965192850423\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7198965192850423\n",
      "Epoch 7/10, Loss: 0.1095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.66      0.68      1841\n",
      "         1.0       0.75      0.78      0.77      2411\n",
      "\n",
      "    accuracy                           0.73      4252\n",
      "   macro avg       0.73      0.72      0.72      4252\n",
      "weighted avg       0.73      0.73      0.73      4252\n",
      "\n",
      "auc:0.8034616823895366 accuracy:0.7304797742238947\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7304797742238947\n",
      "Epoch 9/10, Loss: 0.0436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.81      0.72      1841\n",
      "         1.0       0.82      0.65      0.73      2411\n",
      "\n",
      "    accuracy                           0.72      4252\n",
      "   macro avg       0.73      0.73      0.72      4252\n",
      "weighted avg       0.74      0.72      0.72      4252\n",
      "\n",
      "auc:0.8175753173655689 accuracy:0.7220131702728128\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7220131702728128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.73      0.71      1841\n",
      "         1.0       0.78      0.76      0.77      2411\n",
      "\n",
      "    accuracy                           0.74      4252\n",
      "   macro avg       0.74      0.74      0.74      4252\n",
      "weighted avg       0.74      0.74      0.74      4252\n",
      "\n",
      "auc:0.8163311330401962 accuracy:0.7424741298212606\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7424741298212606\n",
      "Epoch 1/10, Loss: 0.7571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.15      0.25      1841\n",
      "         1.0       0.59      0.92      0.72      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.59      0.54      0.48      4252\n",
      "weighted avg       0.59      0.59      0.51      4252\n",
      "\n",
      "auc:0.5986528339353556 accuracy:0.5893697083725306\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5893697083725306\n",
      "Epoch 3/10, Loss: 0.5338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53      1841\n",
      "         1.0       0.67      0.93      0.78      2411\n",
      "\n",
      "    accuracy                           0.70      4252\n",
      "   macro avg       0.74      0.66      0.66      4252\n",
      "weighted avg       0.73      0.70      0.67      4252\n",
      "\n",
      "auc:0.802730604411115 accuracy:0.6982596425211665\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6982596425211665\n",
      "Epoch 5/10, Loss: 0.1390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.73      0.75      1841\n",
      "         1.0       0.80      0.84      0.82      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.79      0.78      0.79      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8687285844280166 accuracy:0.7920978363123237\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7920978363123237\n",
      "Epoch 7/10, Loss: 0.0311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.72      0.76      1841\n",
      "         1.0       0.80      0.86      0.83      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.80      0.79      0.79      4252\n",
      "weighted avg       0.80      0.80      0.80      4252\n",
      "\n",
      "auc:0.8827348669674637 accuracy:0.8012699905926622\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8012699905926622\n",
      "Epoch 9/10, Loss: 0.0118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.61      0.71      1841\n",
      "         1.0       0.76      0.92      0.83      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.80      0.77      0.77      4252\n",
      "weighted avg       0.80      0.79      0.78      4252\n",
      "\n",
      "auc:0.8790479359607233 accuracy:0.7859830667920978\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7859830667920978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.65      0.73      1841\n",
      "         1.0       0.77      0.89      0.83      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.80      0.77      0.78      4252\n",
      "weighted avg       0.79      0.79      0.78      4252\n",
      "\n",
      "auc:0.8700064501579421 accuracy:0.7888052681091251\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7888052681091251\n",
      "Epoch 1/10, Loss: 0.5950\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.03      0.06      1841\n",
      "         1.0       0.57      0.98      0.72      2411\n",
      "\n",
      "    accuracy                           0.57      4252\n",
      "   macro avg       0.60      0.51      0.39      4252\n",
      "weighted avg       0.59      0.57      0.44      4252\n",
      "\n",
      "auc:0.5987350661270734 accuracy:0.5726716839134525\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5726716839134525\n",
      "Epoch 3/10, Loss: 0.5187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44      1841\n",
      "         1.0       0.63      0.88      0.73      2411\n",
      "\n",
      "    accuracy                           0.64      4252\n",
      "   macro avg       0.65      0.60      0.59      4252\n",
      "weighted avg       0.65      0.64      0.61      4252\n",
      "\n",
      "auc:0.6913026052284804 accuracy:0.6389934148635936\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6389934148635936\n",
      "Epoch 5/10, Loss: 0.3145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.62      0.64      1841\n",
      "         1.0       0.72      0.76      0.74      2411\n",
      "\n",
      "    accuracy                           0.70      4252\n",
      "   macro avg       0.69      0.69      0.69      4252\n",
      "weighted avg       0.70      0.70      0.70      4252\n",
      "\n",
      "auc:0.7678393728184532 accuracy:0.6999059266227657\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6999059266227657\n",
      "Epoch 7/10, Loss: 0.0302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.71      0.68      1841\n",
      "         1.0       0.76      0.72      0.74      2411\n",
      "\n",
      "    accuracy                           0.72      4252\n",
      "   macro avg       0.71      0.71      0.71      4252\n",
      "weighted avg       0.72      0.72      0.72      4252\n",
      "\n",
      "auc:0.7852602063104308 accuracy:0.7151928504233303\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7151928504233303\n",
      "Epoch 9/10, Loss: 0.0012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.66      1841\n",
      "         1.0       0.74      0.79      0.77      2411\n",
      "\n",
      "    accuracy                           0.72      4252\n",
      "   macro avg       0.72      0.71      0.72      4252\n",
      "weighted avg       0.72      0.72      0.72      4252\n",
      "\n",
      "auc:0.7953837776387465 accuracy:0.7241298212605832\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7241298212605832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.69      0.68      1841\n",
      "         1.0       0.76      0.75      0.75      2411\n",
      "\n",
      "    accuracy                           0.72      4252\n",
      "   macro avg       0.72      0.72      0.72      4252\n",
      "weighted avg       0.72      0.72      0.72      4252\n",
      "\n",
      "auc:0.7909470692784812 accuracy:0.7222483537158984\n",
      "Params: {'epochs': 10, 'lr': 0.0001, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7222483537158984\n",
      "Epoch 1/10, Loss: 0.7053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.14      0.23      1841\n",
      "         1.0       0.58      0.93      0.72      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.59      0.53      0.47      4252\n",
      "weighted avg       0.59      0.59      0.50      4252\n",
      "\n",
      "auc:0.5736463623745143 accuracy:0.5851364063969896\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5851364063969896\n",
      "Epoch 3/10, Loss: 0.4642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.22      0.34      1841\n",
      "         1.0       0.61      0.92      0.73      2411\n",
      "\n",
      "    accuracy                           0.62      4252\n",
      "   macro avg       0.64      0.57      0.53      4252\n",
      "weighted avg       0.64      0.62      0.56      4252\n",
      "\n",
      "auc:0.6328005963974188 accuracy:0.6182972718720602\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6182972718720602\n",
      "Epoch 5/10, Loss: 0.3991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.54      0.59      1841\n",
      "         1.0       0.69      0.79      0.74      2411\n",
      "\n",
      "    accuracy                           0.68      4252\n",
      "   macro avg       0.68      0.66      0.67      4252\n",
      "weighted avg       0.68      0.68      0.67      4252\n",
      "\n",
      "auc:0.6858394588806374 accuracy:0.680620884289746\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.680620884289746\n",
      "Epoch 7/10, Loss: 0.3467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.65      0.65      1841\n",
      "         1.0       0.73      0.74      0.74      2411\n",
      "\n",
      "    accuracy                           0.70      4252\n",
      "   macro avg       0.70      0.70      0.70      4252\n",
      "weighted avg       0.70      0.70      0.70      4252\n",
      "\n",
      "auc:0.7289789172430994 accuracy:0.7022577610536218\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7022577610536218\n",
      "Epoch 9/10, Loss: 0.2171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.67      0.66      1841\n",
      "         1.0       0.75      0.73      0.74      2411\n",
      "\n",
      "    accuracy                           0.71      4252\n",
      "   macro avg       0.70      0.70      0.70      4252\n",
      "weighted avg       0.71      0.71      0.71      4252\n",
      "\n",
      "auc:0.7484023862204982 accuracy:0.7060206961429916\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7060206961429916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.59      0.64      1841\n",
      "         1.0       0.72      0.81      0.76      2411\n",
      "\n",
      "    accuracy                           0.71      4252\n",
      "   macro avg       0.71      0.70      0.70      4252\n",
      "weighted avg       0.71      0.71      0.71      4252\n",
      "\n",
      "auc:0.7555417175173267 accuracy:0.7121354656632173\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7121354656632173\n",
      "Epoch 1/10, Loss: 0.5336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.35      0.43      1841\n",
      "         1.0       0.61      0.77      0.68      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.58      0.56      0.56      4252\n",
      "weighted avg       0.58      0.59      0.57      4252\n",
      "\n",
      "auc:0.5445294076961671 accuracy:0.5910159924741298\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5910159924741298\n",
      "Epoch 3/10, Loss: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.71      0.60      1841\n",
      "         1.0       0.70      0.50      0.58      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.61      0.61      0.59      4252\n",
      "weighted avg       0.62      0.59      0.59      4252\n",
      "\n",
      "auc:0.5941087731385053 accuracy:0.5926622765757291\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5926622765757291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.71      0.60      1841\n",
      "         1.0       0.70      0.50      0.58      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.61      0.61      0.59      4252\n",
      "weighted avg       0.62      0.59      0.59      4252\n",
      "\n",
      "auc:0.5941087731385053 accuracy:0.5926622765757291\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5926622765757291\n",
      "Epoch 1/10, Loss: 0.6873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.01      0.03      1841\n",
      "         1.0       0.57      0.99      0.72      2411\n",
      "\n",
      "    accuracy                           0.57      4252\n",
      "   macro avg       0.58      0.50      0.38      4252\n",
      "weighted avg       0.58      0.57      0.42      4252\n",
      "\n",
      "auc:0.5003378278670705 accuracy:0.5689087488240828\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5689087488240828\n",
      "Epoch 3/10, Loss: 0.6049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.17      0.26      1841\n",
      "         1.0       0.59      0.91      0.71      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.58      0.54      0.49      4252\n",
      "weighted avg       0.58      0.59      0.52      4252\n",
      "\n",
      "auc:0.5548905512057605 accuracy:0.5867826904985889\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5867826904985889\n",
      "Epoch 5/10, Loss: 0.6917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.33      0.42      1841\n",
      "         1.0       0.62      0.82      0.70      2411\n",
      "\n",
      "    accuracy                           0.61      4252\n",
      "   macro avg       0.60      0.58      0.56      4252\n",
      "weighted avg       0.60      0.61      0.58      4252\n",
      "\n",
      "auc:0.5811619341101609 accuracy:0.6084195672624647\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6084195672624647\n",
      "Epoch 7/10, Loss: 0.6304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.40      0.48      1841\n",
      "         1.0       0.64      0.81      0.71      2411\n",
      "\n",
      "    accuracy                           0.63      4252\n",
      "   macro avg       0.63      0.60      0.60      4252\n",
      "weighted avg       0.63      0.63      0.61      4252\n",
      "\n",
      "auc:0.6009542088350718 accuracy:0.632173095014111\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.632173095014111\n",
      "Epoch 9/10, Loss: 0.6075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.57      0.57      1841\n",
      "         1.0       0.67      0.67      0.67      2411\n",
      "\n",
      "    accuracy                           0.63      4252\n",
      "   macro avg       0.62      0.62      0.62      4252\n",
      "weighted avg       0.63      0.63      0.63      4252\n",
      "\n",
      "auc:0.6146971230673464 accuracy:0.6274694261523989\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6274694261523989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.67      0.60      1841\n",
      "         1.0       0.69      0.57      0.63      2411\n",
      "\n",
      "    accuracy                           0.61      4252\n",
      "   macro avg       0.62      0.62      0.61      4252\n",
      "weighted avg       0.63      0.61      0.62      4252\n",
      "\n",
      "auc:0.6189822087837048 accuracy:0.6142991533396049\n",
      "Params: {'epochs': 10, 'lr': 1e-06, 'model_name': 'vit_small_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.6142991533396049\n",
      "Epoch 1/30, Loss: 0.6730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.19      0.29      1841\n",
      "         1.0       0.60      0.92      0.72      2411\n",
      "\n",
      "    accuracy                           0.60      4252\n",
      "   macro avg       0.62      0.55      0.51      4252\n",
      "weighted avg       0.62      0.60      0.54      4252\n",
      "\n",
      "auc:0.6310124404914916 accuracy:0.603480714957667\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.603480714957667\n",
      "Epoch 3/30, Loss: 0.3954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.85      0.73      1841\n",
      "         1.0       0.85      0.63      0.72      2411\n",
      "\n",
      "    accuracy                           0.73      4252\n",
      "   macro avg       0.74      0.74      0.73      4252\n",
      "weighted avg       0.76      0.73      0.73      4252\n",
      "\n",
      "auc:0.822961300629403 accuracy:0.7260112888052681\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7260112888052681\n",
      "Epoch 5/30, Loss: 0.0746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.80      0.76      1841\n",
      "         1.0       0.83      0.76      0.79      2411\n",
      "\n",
      "    accuracy                           0.78      4252\n",
      "   macro avg       0.77      0.78      0.77      4252\n",
      "weighted avg       0.78      0.78      0.78      4252\n",
      "\n",
      "auc:0.8570340402973785 accuracy:0.7751646284101599\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7751646284101599\n",
      "Epoch 7/30, Loss: 0.0200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.64      0.72      1841\n",
      "         1.0       0.77      0.90      0.83      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.80      0.77      0.78      4252\n",
      "weighted avg       0.79      0.79      0.78      4252\n",
      "\n",
      "auc:0.8593216722828625 accuracy:0.7869238005644402\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7869238005644402\n",
      "Epoch 9/30, Loss: 0.0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.62      0.71      1841\n",
      "         1.0       0.76      0.91      0.83      2411\n",
      "\n",
      "    accuracy                           0.78      4252\n",
      "   macro avg       0.80      0.76      0.77      4252\n",
      "weighted avg       0.79      0.78      0.78      4252\n",
      "\n",
      "auc:0.8696716637554969 accuracy:0.784101599247413\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.784101599247413\n",
      "Epoch 11/30, Loss: 0.0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.86      0.76      1841\n",
      "         1.0       0.87      0.70      0.78      2411\n",
      "\n",
      "    accuracy                           0.77      4252\n",
      "   macro avg       0.78      0.78      0.77      4252\n",
      "weighted avg       0.79      0.77      0.77      4252\n",
      "\n",
      "auc:0.8705906366596518 accuracy:0.7706961429915334\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7706961429915334\n",
      "Epoch 13/30, Loss: 0.0094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      1841\n",
      "         1.0       0.80      0.83      0.82      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.78      0.78      0.78      4252\n",
      "weighted avg       0.79      0.79      0.79      4252\n",
      "\n",
      "auc:0.8613054957463426 accuracy:0.7873941674506115\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7873941674506115\n",
      "Epoch 15/30, Loss: 0.0008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.76      0.76      1841\n",
      "         1.0       0.82      0.83      0.82      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.79      0.79      0.79      4252\n",
      "weighted avg       0.80      0.80      0.80      4252\n",
      "\n",
      "auc:0.8793854258872797 accuracy:0.7979774223894638\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7979774223894638\n",
      "Epoch 17/30, Loss: 0.0030\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.77      1841\n",
      "         1.0       0.85      0.78      0.81      2411\n",
      "\n",
      "    accuracy                           0.79      4252\n",
      "   macro avg       0.79      0.80      0.79      4252\n",
      "weighted avg       0.80      0.79      0.79      4252\n",
      "\n",
      "auc:0.8767098381918291 accuracy:0.7935089369708372\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7935089369708372\n",
      "Epoch 19/30, Loss: 0.0056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.79      1841\n",
      "         1.0       0.83      0.86      0.85      2411\n",
      "\n",
      "    accuracy                           0.82      4252\n",
      "   macro avg       0.82      0.82      0.82      4252\n",
      "weighted avg       0.82      0.82      0.82      4252\n",
      "\n",
      "auc:0.8895481983152087 accuracy:0.8226716839134525\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8226716839134525\n",
      "Epoch 21/30, Loss: 0.0143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.52      0.66      1841\n",
      "         1.0       0.72      0.97      0.83      2411\n",
      "\n",
      "    accuracy                           0.77      4252\n",
      "   macro avg       0.82      0.74      0.75      4252\n",
      "weighted avg       0.81      0.77      0.76      4252\n",
      "\n",
      "auc:0.8894589820195371 accuracy:0.772107243650047\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.772107243650047\n",
      "Epoch 23/30, Loss: 0.0011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79      1841\n",
      "         1.0       0.85      0.81      0.83      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.81      0.81      0.81      4252\n",
      "weighted avg       0.81      0.81      0.81      4252\n",
      "\n",
      "auc:0.8878740410093067 accuracy:0.8104421448730009\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8104421448730009\n",
      "Epoch 25/30, Loss: 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79      1841\n",
      "         1.0       0.84      0.82      0.83      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.81      0.81      0.81      4252\n",
      "weighted avg       0.81      0.81      0.81      4252\n",
      "\n",
      "auc:0.8891167609257857 accuracy:0.8125587958607714\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8125587958607714\n",
      "Epoch 27/30, Loss: 0.0025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.78      1841\n",
      "         1.0       0.84      0.81      0.82      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.80      0.80      0.80      4252\n",
      "weighted avg       0.80      0.80      0.80      4252\n",
      "\n",
      "auc:0.8844831458927498 accuracy:0.8029162746942615\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8029162746942615\n",
      "Epoch 29/30, Loss: 0.0019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.78      0.79      1841\n",
      "         1.0       0.83      0.85      0.84      2411\n",
      "\n",
      "    accuracy                           0.82      4252\n",
      "   macro avg       0.81      0.81      0.81      4252\n",
      "weighted avg       0.82      0.82      0.82      4252\n",
      "\n",
      "auc:0.8938846509896813 accuracy:0.8158513640639699\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8158513640639699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.63      0.73      1841\n",
      "         1.0       0.77      0.93      0.84      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.82      0.78      0.79      4252\n",
      "weighted avg       0.81      0.80      0.79      4252\n",
      "\n",
      "auc:0.8899316481516569 accuracy:0.7986829727187206\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_base_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7986829727187206\n",
      "Epoch 1/30, Loss: 0.6390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.07      0.14      1841\n",
      "         1.0       0.58      0.98      0.73      2411\n",
      "\n",
      "    accuracy                           0.59      4252\n",
      "   macro avg       0.66      0.53      0.43      4252\n",
      "weighted avg       0.65      0.59      0.47      4252\n",
      "\n",
      "auc:0.6456752288026248 accuracy:0.5884289746001882\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.5884289746001882\n",
      "Epoch 3/30, Loss: 0.2597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.74      0.76      1841\n",
      "         1.0       0.81      0.84      0.83      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.80      0.79      0.80      4252\n",
      "weighted avg       0.80      0.80      0.80      4252\n",
      "\n",
      "auc:0.875149679485952 accuracy:0.8010348071495766\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8010348071495766\n",
      "Epoch 5/30, Loss: 0.0121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.76      0.77      1841\n",
      "         1.0       0.82      0.84      0.83      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.80      0.80      0.80      4252\n",
      "weighted avg       0.81      0.81      0.81      4252\n",
      "\n",
      "auc:0.8846557208485191 accuracy:0.8069143932267169\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8069143932267169\n",
      "Epoch 7/30, Loss: 0.0746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77      1841\n",
      "         1.0       0.83      0.80      0.82      2411\n",
      "\n",
      "    accuracy                           0.80      4252\n",
      "   macro avg       0.79      0.80      0.79      4252\n",
      "weighted avg       0.80      0.80      0.80      4252\n",
      "\n",
      "auc:0.8757678853327284 accuracy:0.7958607714016933\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.7958607714016933\n",
      "Epoch 9/30, Loss: 0.0023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.80      0.78      1841\n",
      "         1.0       0.84      0.81      0.83      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.80      0.81      0.80      4252\n",
      "weighted avg       0.81      0.81      0.81      4252\n",
      "\n",
      "auc:0.8873509090937766 accuracy:0.8073847601128881\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8073847601128881\n",
      "Epoch 11/30, Loss: 0.0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.85      0.79      1841\n",
      "         1.0       0.87      0.77      0.82      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.81      0.81      0.80      4252\n",
      "weighted avg       0.81      0.81      0.81      4252\n",
      "\n",
      "auc:0.8924306056051714 accuracy:0.8057384760112888\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8057384760112888\n",
      "Epoch 13/30, Loss: 0.0025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.67      0.76      1841\n",
      "         1.0       0.79      0.92      0.85      2411\n",
      "\n",
      "    accuracy                           0.81      4252\n",
      "   macro avg       0.83      0.80      0.80      4252\n",
      "weighted avg       0.82      0.81      0.81      4252\n",
      "\n",
      "auc:0.8895941582251005 accuracy:0.8146754468485419\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8146754468485419\n",
      "Epoch 15/30, Loss: 0.0020\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79      1841\n",
      "         1.0       0.85      0.83      0.84      2411\n",
      "\n",
      "    accuracy                           0.82      4252\n",
      "   macro avg       0.81      0.82      0.82      4252\n",
      "weighted avg       0.82      0.82      0.82      4252\n",
      "\n",
      "auc:0.8988800876662754 accuracy:0.8184383819379115\n",
      "Params: {'epochs': 30, 'lr': 1e-05, 'model_name': 'vit_large_patch16_224', 'num_classes': 2, 'pretrained': True}, Validation Accuracy: 0.8184383819379115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 169\u001b[0m\n\u001b[1;32m    160\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit_base_patch16_224\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit_large_patch16_224\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit_small_patch16_224\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m50\u001b[39m],\n\u001b[1;32m    166\u001b[0m }\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m best_params, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 135\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(dataset, param_grid)\u001b[0m\n\u001b[1;32m    133\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m    134\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 135\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BCIT/lib/python3.10/site-packages/torch/optim/adam.py:543\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    540\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    542\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n\u001b[0;32m--> 543\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_addcmul_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Delete the local intermediate since it won't be used anymore to save on peak memory\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m device_grads\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import cv2\n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "def frame(imagen_path, umbral_oscuridad=60, canny_umbral1=120, canny_umbral2=250):\n",
    "    \"\"\"\n",
    "    Extrae las zonas dentro de los bordes de regiones oscuras de una imagen.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_color = cv2.cvtColor(cv2.imread(imagen_path), cv2.COLOR_BGR2RGB)  # Imagen en color en formato RGB\n",
    "\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"No se pudo cargar la imagen desde {imagen_path}\")\n",
    "\n",
    "    # Crear una mÃ¡scara binaria de regiones oscuras\n",
    "    mascara_oscura = cv2.threshold(img, umbral_oscuridad, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    # Aplicar Canny solo a regiones oscuras\n",
    "    regiones_oscuras = cv2.bitwise_and(img, img, mask=mascara_oscura)\n",
    "    bordes = cv2.Canny(regiones_oscuras, canny_umbral1, canny_umbral2)\n",
    "\n",
    "    # Cerrar los bordes para formar regiones completas\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    bordes_cerrados = cv2.morphologyEx(bordes, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contornos, _ = cv2.findContours(bordes_cerrados, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Crear una nueva mÃ¡scara y rellenar los contornos\n",
    "    mascara_rellena = np.zeros_like(img)\n",
    "    cv2.drawContours(mascara_rellena, contornos, -1, color=255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Aplicar la mÃ¡scara rellena a la imagen original en color\n",
    "    resultado = cv2.bitwise_and(img_color, img_color, mask=mascara_rellena)\n",
    "\n",
    "\n",
    "\n",
    "    return resultado\n",
    "\n",
    "# Define a custom dataset class for EEG data\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.point(lambda p: p > 128 and 255)\n",
    "\n",
    "        \n",
    "        frame_img = Image.fromarray(frame(img_path, umbral_oscuridad=100, mostrar=True))\n",
    "        image = Image.fromarray(frame_img)\n",
    "\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "\n",
    "# Vision Transformer-based EEG classifier\n",
    "class EEGVisionTransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, model_name='vit_base_patch16_224', pretrained=True):\n",
    "        super(EEGVisionTransformerClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Data processing function\n",
    "def preprocess_eeg_data(df):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    dataset = EEGDataset(df, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "# Train, validation, and test split\n",
    "def split_data(dataset, train_ratio=0.7, val_ratio=0.15):\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = int(val_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    return random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classifier_assessment(y_test, predicted):\n",
    "    confusion_mc = confusion_matrix(y_test, predicted)\n",
    "    report = classification_report(y_test, predicted)\n",
    "    print(report)\n",
    "    confusion_mc = confusion_mc / np.sum(confusion_mc, axis=1)[:, np.newaxis]\n",
    "    classes = list(set(y_test))\n",
    "    df_cm = pd.DataFrame(confusion_mc, index=classes, columns=classes)\n",
    "\n",
    "    # plt.figure(figsize=(5.5, 4))\n",
    "    # sns.heatmap(df_cm, annot=True)\n",
    "    # plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test, predicted)))\n",
    "    # plt.ylabel('True label')\n",
    "    # plt.xlabel('Predicted label')\n",
    "    return report\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            all_prob.extend(outputs[:, 1].cpu().numpy())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    report = classifier_assessment(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_prob)\n",
    "    accuracy_global = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f'auc:{auc} accuracy:{accuracy_global}')\n",
    "    return accuracy_global, report\n",
    "\n",
    "# Grid search for hyperparameter optimization\n",
    "def grid_search(dataset, param_grid):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    train_data, val_data, test_data = split_data(dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=24, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=24, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=24, shuffle=False)\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = EEGVisionTransformerClassifier(\n",
    "            num_classes=params['num_classes'],\n",
    "            model_name=params['model_name'],\n",
    "            pretrained=params['pretrained']\n",
    "        )\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "        loss_tmp = 1\n",
    "        # Training loop\n",
    "        for epoch in range(params['epochs']):\n",
    "            model.train()\n",
    "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{params[\"epochs\"]}')\n",
    "            running_loss = 0.0\n",
    "            #for images, labels in train_loader:\n",
    "            for images, labels in progress_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                progress_bar.set_postfix({'loss': running_loss/(progress_bar.n+1)})\n",
    "            if epoch % 2 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{params['epochs']}, Loss: {loss.item():.4f}\")\n",
    "                accuracy, report = test_model(model, val_loader)\n",
    "\n",
    "                print(f\"Params: {params}, Validation Accuracy: {accuracy}\")\n",
    "                if loss > loss_tmp + 0.1:\n",
    "                    break\n",
    "                loss_tmp = loss\n",
    "            running_loss += loss.item()\n",
    "            with open('/home/castrogaray-j/U_Winnipeg_OneDrive/Digital_image_processing/BCIT_spectrogram/best_model.pkl', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            progress_bar.set_postfix({'loss': running_loss/(progress_bar.n+1)})\n",
    "\n",
    "        accuracy, report = test_model(model, val_loader)\n",
    "        print(f\"Params: {params}, Validation Accuracy: {accuracy}\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    print(f\"Best Params: {best_params}, Best Validation Accuracy: {best_accuracy}\")\n",
    "    test_model(best_model, test_loader)\n",
    "    return best_params, best_model\n",
    "\n",
    "# Preprocess data\n",
    "dataset = preprocess_eeg_data(df)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'model_name': ['vit_large_patch16_224'],\n",
    "    'pretrained': [True],\n",
    "    'num_classes': [2],  # Set to the number of unique classes\n",
    "    'lr': [1e-5],\n",
    "    'epochs': [20]\n",
    "}\n",
    "# Perform grid search\n",
    "#best_params, best_model = grid_search(dataset, param_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641612a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T14:33:13.801576Z",
     "iopub.status.busy": "2025-04-15T14:33:13.801351Z",
     "iopub.status.idle": "2025-04-15T14:57:58.170427Z",
     "shell.execute_reply": "2025-04-15T14:57:58.169885Z",
     "shell.execute_reply.started": "2025-04-15T14:33:13.801559Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "import cv2\n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "def frame(imagen_path, umbral_oscuridad=60, canny_umbral1=120, canny_umbral2=250):\n",
    "    \"\"\"\n",
    "    Extrae las zonas dentro de los bordes de regiones oscuras de una imagen.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_color = cv2.cvtColor(cv2.imread(imagen_path), cv2.COLOR_BGR2RGB)  # Imagen en color en formato RGB\n",
    "\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"No se pudo cargar la imagen desde {imagen_path}\")\n",
    "\n",
    "    # Crear una mÃ¡scara binaria de regiones oscuras\n",
    "    mascara_oscura = cv2.threshold(img, umbral_oscuridad, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    # Aplicar Canny solo a regiones oscuras\n",
    "    regiones_oscuras = cv2.bitwise_and(img, img, mask=mascara_oscura)\n",
    "    bordes = cv2.Canny(regiones_oscuras, canny_umbral1, canny_umbral2)\n",
    "\n",
    "    # Cerrar los bordes para formar regiones completas\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    bordes_cerrados = cv2.morphologyEx(bordes, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contornos, _ = cv2.findContours(bordes_cerrados, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Crear una nueva mÃ¡scara y rellenar los contornos\n",
    "    mascara_rellena = np.zeros_like(img)\n",
    "    cv2.drawContours(mascara_rellena, contornos, -1, color=255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Aplicar la mÃ¡scara rellena a la imagen original en color\n",
    "    resultado = cv2.bitwise_and(img_color, img_color, mask=mascara_rellena)\n",
    "\n",
    "\n",
    "\n",
    "    return resultado\n",
    "\n",
    "# Define a custom dataset class for EEG data\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.point(lambda p: p > 128 and 255)\n",
    "\n",
    "        \n",
    "        frame_img = Image.fromarray(frame(img_path, umbral_oscuridad=100, mostrar=True))\n",
    "        image = Image.fromarray(frame_img)\n",
    "\n",
    "        label = self.df.iloc[idx]['label']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "\n",
    "# Vision Transformer-based EEG classifier\n",
    "class EEGVisionTransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, model_name='vit_base_patch16_224', pretrained=True):\n",
    "        super(EEGVisionTransformerClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Data processing function\n",
    "def preprocess_eeg_data(df):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    dataset = EEGDataset(df, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "# Train, validation, and test split\n",
    "def split_data(dataset, train_ratio=0.7, val_ratio=0.15):\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = int(val_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    return random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classifier_assessment(y_test, predicted):\n",
    "    confusion_mc = confusion_matrix(y_test, predicted)\n",
    "    report = classification_report(y_test, predicted)\n",
    "    print(report)\n",
    "    confusion_mc = confusion_mc / np.sum(confusion_mc, axis=1)[:, np.newaxis]\n",
    "    classes = list(set(y_test))\n",
    "    df_cm = pd.DataFrame(confusion_mc, index=classes, columns=classes)\n",
    "\n",
    "    # plt.figure(figsize=(5.5, 4))\n",
    "    # sns.heatmap(df_cm, annot=True)\n",
    "    # plt.title('Accuracy:{0:.3f}'.format(accuracy_score(y_test, predicted)))\n",
    "    # plt.ylabel('True label')\n",
    "    # plt.xlabel('Predicted label')\n",
    "    return report\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            all_prob.extend(outputs[:, 1].cpu().numpy())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    report = classifier_assessment(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_prob)\n",
    "    accuracy_global = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f'auc:{auc} accuracy:{accuracy_global}')\n",
    "    return accuracy_global, report\n",
    "\n",
    "# Grid search for hyperparameter optimization\n",
    "def grid_search(dataset, param_grid):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    train_data, val_data, test_data = split_data(dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=24, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=24, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=24, shuffle=False)\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = EEGVisionTransformerClassifier(\n",
    "            num_classes=params['num_classes'],\n",
    "            model_name=params['model_name'],\n",
    "            pretrained=params['pretrained']\n",
    "        )\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "        loss_tmp = 1\n",
    "        # Training loop\n",
    "        for epoch in range(params['epochs']):\n",
    "            model.train()\n",
    "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{params[\"epochs\"]}')\n",
    "            running_loss = 0.0\n",
    "            #for images, labels in train_loader:\n",
    "            for images, labels in progress_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                progress_bar.set_postfix({'loss': running_loss/(progress_bar.n+1)})\n",
    "            if epoch % 2 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{params['epochs']}, Loss: {loss.item():.4f}\")\n",
    "                accuracy, report = test_model(model, val_loader)\n",
    "\n",
    "                print(f\"Params: {params}, Validation Accuracy: {accuracy}\")\n",
    "                if loss > loss_tmp + 0.1:\n",
    "                    break\n",
    "                loss_tmp = loss\n",
    "            running_loss += loss.item()\n",
    "            with open('/home/castrogaray-j/U_Winnipeg_OneDrive/Digital_image_processing/BCIT_spectrogram/best_model.pkl', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            progress_bar.set_postfix({'loss': running_loss/(progress_bar.n+1)})\n",
    "\n",
    "        accuracy, report = test_model(model, val_loader)\n",
    "        print(f\"Params: {params}, Validation Accuracy: {accuracy}\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    print(f\"Best Params: {best_params}, Best Validation Accuracy: {best_accuracy}\")\n",
    "    test_model(best_model, test_loader)\n",
    "    return best_params, best_model\n",
    "\n",
    "# Preprocess data\n",
    "dataset = preprocess_eeg_data(df)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'model_name': ['vit_large_patch16_224'],\n",
    "    'pretrained': [True],\n",
    "    'num_classes': [2],  # Set to the number of unique classes\n",
    "    'lr': [1e-5],\n",
    "    'epochs': [20]\n",
    "}\n",
    "# Perform grid search\n",
    "#best_params, best_model = grid_search(dataset, param_grid) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
